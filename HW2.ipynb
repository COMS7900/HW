{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUXuP0n8tnhr"
      },
      "source": [
        "# Blazing Hawks\n",
        "Clifford Jones\\\n",
        "Dongyu Liu\\\n",
        "Yuan Chen\n",
        "\n",
        "\n",
        "**A.I. Disclaimer: Work for this assignment was completed with the aid of artificial intelligence tools.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39MIPC4atnhv"
      },
      "source": [
        "## Bisection Method vs Newton Method\n",
        "First come with the example of one variable function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHjzO8lEtnhw",
        "outputId": "47d53ce4-bbea-4a18-83b2-4885190ca7bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Bisection Method Iterations:\n",
            "converged after 0 iterations\n",
            "\n",
            "Bisection method result: 0.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def f(x):\n",
        "    # Cube root function, works for negative x too.\n",
        "    return np.cbrt(x)\n",
        "\n",
        "\n",
        "def bisection_method(a, b, tol=1e-8, max_iter=100):\n",
        "    if f(a)*f(b) >= 0:\n",
        "        print(\"Bisection method fails: f(a) and f(b) must have opposite signs.\")\n",
        "        return None\n",
        "    print(\"\\nBisection Method Iterations:\")\n",
        "    for i in range(max_iter):\n",
        "        c = (a + b) / 2.0\n",
        "        fc = f(c)\n",
        "        if abs(fc) < tol or (b - a)/2 < tol:\n",
        "            print(\"converged after\", i, \"iterations\")\n",
        "            return c\n",
        "        if f(a)*fc < 0:\n",
        "            b = c\n",
        "        else:\n",
        "            a = c\n",
        "    return (a + b) / 2.0\n",
        "\n",
        "\n",
        "# Bisection method: choose an interval that brackets the root.\n",
        "a, b = -1, 1  # f(-1) = -1, f(1) = 1 so the sign change condition holds.\n",
        "bisection_root = bisection_method(a, b)\n",
        "print(\"\\nBisection method result:\", bisection_root)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def fprime(x):\n",
        "    # Derivative: 1/(3*(|x|^(2/3))).\n",
        "    # Avoid division by zero.\n",
        "    if x == 0:\n",
        "        raise ZeroDivisionError(\"Derivative undefined at x=0\")\n",
        "    return 1 / (3 * np.cbrt(x**2))\n",
        "\n",
        "def newton_method(x0, tol=1e-8, max_iter=20):\n",
        "    x = x0\n",
        "    print(\"Newton's Method Iterations:\")\n",
        "    for i in range(max_iter):\n",
        "        try:\n",
        "            fp = fprime(x)\n",
        "        except ZeroDivisionError:\n",
        "            print(f\"Iteration {i}: Derivative zero at x={x}.\")\n",
        "            return None\n",
        "        x_new = x - f(x) / fp\n",
        "        print(f\"Iteration {i}: x = {x_new}\")\n",
        "        if abs(x_new - x) < tol:\n",
        "            print(f\"Converged after {i} iterations.\")\n",
        "            return x_new\n",
        "        x = x_new\n",
        "    return x\n",
        "\n",
        "# For f(x) = cbrt(x), the only root is at x = 0.\n",
        "# Newton's method starting from x0 != 0 will not converge.\n",
        "x0 = 1.0\n",
        "newton_root = newton_method(x0)\n",
        "print(\"\\nNewton's method result:\", newton_root)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## For mult variables. \n",
        "In these two methods, we can only use Newton method with Hessian Matrix for multiple variables questions.\\\n",
        "Slove the equation parameters with least square method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 iteration: beta = [0. 0. 0.]\n",
            "1 iteration: beta = [3.01124533 4.97041046 6.03920518]\n",
            "Estimated beta: [3.01124533 4.97041046 6.03920518]\n",
            "True beta: [3 5 6]\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "m, n = 100, 3\n",
        "X = np.random.rand(m, n)\n",
        "true_beta = np.array([3,5,6])\n",
        "y = X @ true_beta + np.random.randn(m)*0.1\n",
        "\n",
        "\n",
        "\n",
        "def Newton_method(tol=1e-8, max_iter=20):\n",
        "    beta = np.zeros(n)\n",
        "    for i in range(max_iter):\n",
        "        print(f\"{i} iteration: beta = {beta}\")\n",
        "        gradient = X.T @ (X @ beta - y)\n",
        "        hessian = X.T @ X\n",
        "        beta -= np.linalg.solve(hessian, gradient)\n",
        "        if np.linalg.norm(gradient) < tol:\n",
        "            return beta\n",
        "\n",
        "    print(\"Newton's method did not converge.\")\n",
        "    return beta\n",
        "\n",
        "beta = Newton_method()\n",
        "print(\"Estimated beta:\", beta)\n",
        "print(\"True beta:\", true_beta)\n",
        "    \n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "m, n = 100, 2 # 100 samples, 2 features\n",
        "X = np.random.rand(m, n)\n",
        "true_theta = np.array([3, 5]) # true parameters\n",
        "y_prob = 1 / (1 + np.exp(-X @ true_theta))  # logistic function\n",
        "y = (np.random.rand(m) < y_prob).astype(int)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def logistic_regression_newton(X, y, tol=1e-6, max_iter=10):\n",
        "    m, n = X.shape\n",
        "    theta = np.zeros(n)  # initialize guess at 0\n",
        "    \n",
        "    for i in range(max_iter):\n",
        "        h = sigmoid(X @ theta)\n",
        "        \n",
        "        # get gradient and Hessian matrix\n",
        "        gradient = X.T @ (y - h)\n",
        "        \n",
        "        R = np.diag(h * (1 - h))  # m x m diagonal matrix\n",
        "        H = X.T @ R @ X  # Hessian matrix\n",
        "\n",
        "        # update theta\n",
        "        delta_theta = np.linalg.solve(H, gradient)\n",
        "        theta += delta_theta\n",
        "\n",
        "        # check convergence\n",
        "        if np.linalg.norm(delta_theta) < tol:\n",
        "            print(f\"Converged in {i+1} iterations.\")\n",
        "            return theta\n",
        "    \n",
        "    print(\"Newton's method did not fully converge.\")\n",
        "    return theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converged in 9 iterations.\n",
            "Estimated theta: [2.89835968 8.0589256 ]\n"
          ]
        }
      ],
      "source": [
        "theta_estimated = logistic_regression_newton(X, y)\n",
        "print(\"Estimated theta:\", theta_estimated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIcG47_Ptnhx"
      },
      "source": [
        "## QR decomposition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHq1gs6wtnhx"
      },
      "source": [
        "### Gram-Schmidt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gram_schmidt(A):\n",
        "    \"\"\"\n",
        "    Compute the QR factorization of A using the classical Gramâ€“Schmidt process.\n",
        "    Returns:\n",
        "       Q: m x n matrix with orthonormal columns\n",
        "       R: n x n upper triangular matrix, with A = Q @ R\n",
        "    \"\"\"\n",
        "    m, n = A.shape\n",
        "    Q = np.zeros((m, n))\n",
        "    R = np.zeros((n, n))\n",
        "    for j in range(n):\n",
        "        v = A[:, j].copy()\n",
        "        for i in range(j):\n",
        "            R[i, j] = np.dot(Q[:, i], A[:, j])\n",
        "            v = v - R[i, j] * Q[:, i]\n",
        "        R[j, j] = np.linalg.norm(v)\n",
        "        if np.isclose(R[j, j], 0.0):\n",
        "            raise ValueError(\"Matrix A has linearly dependent columns.\")\n",
        "        Q[:, j] = v / R[j, j]\n",
        "    return Q, R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIVIWHwetnhy",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "### Householder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def householder_qr(A):\n",
        "    \"\"\"\n",
        "    Compute the QR factorization of A using Householder reflections.\n",
        "    Returns:\n",
        "       Q: m x m orthogonal matrix\n",
        "       R: m x n upper triangular matrix, with A = Q @ R\n",
        "    \"\"\"\n",
        "    m, n = A.shape\n",
        "    R = A.copy().astype(float)\n",
        "    Q = np.eye(m)\n",
        "\n",
        "    for k in range(min(m, n)):\n",
        "        # Form the vector to reflect\n",
        "        x = R[k:, k]\n",
        "        norm_x = np.linalg.norm(x)\n",
        "        if np.isclose(norm_x, 0):\n",
        "            continue\n",
        "        # Choose sign to avoid cancellation\n",
        "        sign = -np.sign(x[0]) if x[0] != 0 else -1\n",
        "        u1 = x[0] - sign * norm_x\n",
        "        v = x.copy()\n",
        "        v[0] = u1\n",
        "        v = v / np.linalg.norm(v)\n",
        "\n",
        "        # Build the Householder matrix H_k for the submatrix\n",
        "        Hk = np.eye(m)\n",
        "        Hk[k:, k:] -= 2.0 * np.outer(v, v)\n",
        "\n",
        "        R = Hk @ R\n",
        "        Q = Q @ Hk\n",
        "\n",
        "    return Q, R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WQ5IFeFtnhy"
      },
      "source": [
        "### Given Rotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk2ulunutnhz",
        "outputId": "4764021d-5534-43fa-faa7-28856352b6dc"
      },
      "outputs": [],
      "source": [
        "\n",
        "def givens_qr(A):\n",
        "    \"\"\"\n",
        "    Compute the QR factorization of A using Givens rotations.\n",
        "    Returns:\n",
        "       Q: m x m orthogonal matrix\n",
        "       R: m x n upper triangular matrix, with A = Q @ R\n",
        "    \"\"\"\n",
        "    m, n = A.shape\n",
        "    R = A.copy().astype(float)\n",
        "    Q = np.eye(m)\n",
        "\n",
        "    # Process each column\n",
        "    for j in range(n):\n",
        "        # Zero out the entries below the diagonal in column j\n",
        "        for i in range(j+1, m):\n",
        "            a = R[j, j]\n",
        "            b = R[i, j]\n",
        "            r = np.hypot(a, b)\n",
        "            if np.isclose(r, 0):\n",
        "                continue\n",
        "            c = a / r\n",
        "            s = b / r\n",
        "            # Apply rotation to R: update rows j and i for columns j:n\n",
        "            for k in range(j, n):\n",
        "                temp = c * R[j, k] + s * R[i, k]\n",
        "                R[i, k] = -s * R[j, k] + c * R[i, k]\n",
        "                R[j, k] = temp\n",
        "            # Apply rotation to Q: update columns j and i of Q\n",
        "            temp_j = Q[:, j].copy()\n",
        "            temp_i = Q[:, i].copy()\n",
        "            Q[:, j] = c * temp_j + s * temp_i\n",
        "            Q[:, i] = -s * temp_j + c * temp_i\n",
        "    return Q, R\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matrix A:\n",
            "[[ 1.76405235  0.40015721  0.97873798]\n",
            " [ 2.2408932   1.86755799 -0.97727788]\n",
            " [ 0.95008842 -0.15135721 -0.10321885]\n",
            " [ 0.4105985   0.14404357  1.45427351]]\n",
            "\n",
            "--- Gram-Schmidt QR Factorization ---\n",
            "Q (Gram-Schmidt):\n",
            "[[ 0.581441   -0.47915974  0.25929548]\n",
            " [ 0.73861028  0.64154205 -0.15752491]\n",
            " [ 0.31315418 -0.59551882 -0.46848788]\n",
            " [ 0.13533544 -0.06470756  0.82974144]]\n",
            "R (Gram-Schmidt):\n",
            "[[ 3.0339318   1.58416139  0.01174224]\n",
            " [ 0.          1.08719312 -1.12857042]\n",
            " [ 0.          0.          1.66275572]]\n",
            "Reconstruction (Q_gs @ R_gs):\n",
            "[[ 1.76405235  0.40015721  0.97873798]\n",
            " [ 2.2408932   1.86755799 -0.97727788]\n",
            " [ 0.95008842 -0.15135721 -0.10321885]\n",
            " [ 0.4105985   0.14404357  1.45427351]]\n",
            "\n",
            "--- Householder QR Factorization ---\n",
            "Q (Householder, reduced to first n columns):\n",
            "[[-0.581441    0.47915974  0.25929548]\n",
            " [-0.73861028 -0.64154205 -0.15752491]\n",
            " [-0.31315418  0.59551882 -0.46848788]\n",
            " [-0.13533544  0.06470756  0.82974144]]\n",
            "R (Householder):\n",
            "[[-3.03393180e+00 -1.58416139e+00 -1.17422449e-02]\n",
            " [ 3.05366741e-16 -1.08719312e+00  1.12857042e+00]\n",
            " [ 7.93659740e-17 -8.71248884e-17  1.66275572e+00]\n",
            " [-2.60528696e-16  1.26163761e-16 -1.96074224e-16]]\n",
            "Reconstruction (Q_h_full @ R_h):\n",
            "[[ 1.76405235  0.40015721  0.97873798]\n",
            " [ 2.2408932   1.86755799 -0.97727788]\n",
            " [ 0.95008842 -0.15135721 -0.10321885]\n",
            " [ 0.4105985   0.14404357  1.45427351]]\n",
            "\n",
            "--- Givens QR Factorization ---\n",
            "Q (Givens, reduced to first n columns):\n",
            "[[ 0.581441   -0.47915974  0.25929548]\n",
            " [ 0.73861028  0.64154205 -0.15752491]\n",
            " [ 0.31315418 -0.59551882 -0.46848788]\n",
            " [ 0.13533544 -0.06470756  0.82974144]]\n",
            "R (Givens):\n",
            "[[ 3.03393180e+00  1.58416139e+00  1.17422449e-02]\n",
            " [ 0.00000000e+00  1.08719312e+00 -1.12857042e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  1.66275572e+00]\n",
            " [ 5.55111512e-17  1.38777878e-17  0.00000000e+00]]\n",
            "Reconstruction (Q_giv_full @ R_giv):\n",
            "[[ 1.76405235  0.40015721  0.97873798]\n",
            " [ 2.2408932   1.86755799 -0.97727788]\n",
            " [ 0.95008842 -0.15135721 -0.10321885]\n",
            " [ 0.4105985   0.14404357  1.45427351]]\n",
            "\n",
            "--- Column-by-Column Comparison of Q (up to sign differences) ---\n",
            "\n",
            "Column 0:\n",
            "Gram-Schmidt vs. Householder: Agree\n",
            "Gram-Schmidt vs. Givens: Agree\n",
            "\n",
            "Column 1:\n",
            "Gram-Schmidt vs. Householder: Agree\n",
            "Gram-Schmidt vs. Givens: Agree\n",
            "\n",
            "Column 2:\n",
            "Gram-Schmidt vs. Householder: Agree\n",
            "Gram-Schmidt vs. Givens: Agree\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Main script to compute and compare QR factorizations\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(0)\n",
        "    A = np.random.randn(4, 3)\n",
        "\n",
        "    print(\"Matrix A:\")\n",
        "    print(A)\n",
        "\n",
        "    # 1. Gram-Schmidt QR factorization (reduced Q: m x n)\n",
        "    Q_gs, R_gs = gram_schmidt(A)\n",
        "    print(\"\\n--- Gram-Schmidt QR Factorization ---\")\n",
        "    print(\"Q (Gram-Schmidt):\")\n",
        "    print(Q_gs)\n",
        "    print(\"R (Gram-Schmidt):\")\n",
        "    print(R_gs)\n",
        "    print(\"Reconstruction (Q_gs @ R_gs):\")\n",
        "    print(Q_gs @ R_gs)\n",
        "\n",
        "    # 2. Householder QR factorization (full Q: m x m)\n",
        "    Q_h_full, R_h = householder_qr(A)\n",
        "    # Extract the first n columns for comparison\n",
        "    Q_h = Q_h_full[:, :A.shape[1]]\n",
        "    print(\"\\n--- Householder QR Factorization ---\")\n",
        "    print(\"Q (Householder, reduced to first n columns):\")\n",
        "    print(Q_h)\n",
        "    print(\"R (Householder):\")\n",
        "    print(R_h)\n",
        "    print(\"Reconstruction (Q_h_full @ R_h):\")\n",
        "    print(Q_h_full @ R_h)\n",
        "\n",
        "    # 3. Givens QR factorization (full Q: m x m)\n",
        "    Q_giv_full, R_giv = givens_qr(A)\n",
        "    # Extract the first n columns for comparison\n",
        "    Q_giv = Q_giv_full[:, :A.shape[1]]\n",
        "    print(\"\\n--- Givens QR Factorization ---\")\n",
        "    print(\"Q (Givens, reduced to first n columns):\")\n",
        "    print(Q_giv)\n",
        "    print(\"R (Givens):\")\n",
        "    print(R_giv)\n",
        "    print(\"Reconstruction (Q_giv_full @ R_giv):\")\n",
        "    print(Q_giv_full @ R_giv)\n",
        "\n",
        "    # Compare the Q matrices column by column (up to a possible sign change)\n",
        "    n = A.shape[1]\n",
        "    def same_up_to_sign(u, v):\n",
        "        return np.allclose(u, v) or np.allclose(u, -v)\n",
        "\n",
        "    print(\"\\n--- Column-by-Column Comparison of Q (up to sign differences) ---\")\n",
        "    for i in range(n):\n",
        "        col_gs = Q_gs[:, i]\n",
        "        col_hh = Q_h[:, i]\n",
        "        col_giv = Q_giv[:, i]\n",
        "        print(f\"\\nColumn {i}:\")\n",
        "        print(\"Gram-Schmidt vs. Householder:\", \"Agree\" if same_up_to_sign(col_gs, col_hh) else \"Differ\")\n",
        "        print(\"Gram-Schmidt vs. Givens:\", \"Agree\" if same_up_to_sign(col_gs, col_giv) else \"Differ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Research_Field_01",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
